{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "agricultural-gross",
   "metadata": {},
   "source": [
    "# DQN implementation in JAX\n",
    "\n",
    "This notebook walks through an implementation of [DQN](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf) in [JAX](https://jax.readthedocs.io/en/latest/).\n",
    "There exists a complete [ecosystem](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) of libraries based on JAX to ease the developpement of deep and Reinforcement Learning algorithms, but because this notebook aims at demonstrating its core concepts, the implementation will only rely on \"vanilla\" JAX.\n",
    "\n",
    "## JAX\n",
    "From the official [quickstart](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) documentation:\n",
    "> JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.\n",
    "\n",
    "JAX is based on [XLA](https://www.tensorflow.org/xla) to provide a hardware accelerated backend to linear algebra operations, encapsulated in a NumPy-compatible API. To keep it simple, any numpy code can be replaced by its equivalent jax.numpy to be ported on GPU/TPU and run faster. \n",
    "Moreover, all these operations, as well as some native Python code, can be automatically differentiated, making JAX a good candidate to perform any kind of gradient based optimization.\n",
    "\n",
    "JAX can be defined it as \"an extensible system for composable function transformations\".\n",
    "The most useful transformations include:\n",
    "* `grad`: Automatic differentiation transformation, `grad(func)` returns a function which is the gradient of `func`.\n",
    "* `jit`: \"Just in Time\" compilation. Remember that each JAX array operation rely on a hardware accelerated backend ? Well, your code will most probably contains sequences of this operation, which would result in the backend being called sequentially to execute them. By compiling a sequence of operations, the backend could be called only once for the whole sequence, resulting in faster execution. \n",
    "* `vmap`: Automatic vectorisation transformation, can be used to easily apply operation to full batch instead of single elements.\n",
    "\n",
    "All these transformations can be composed arbitrarily, you can take the gradient of a compiled vectorized funtcion for example: `grad(jit(vmap(f)))`. \n",
    "This transformation system may seem abstract for now, but the notebook contains example use case for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gothic-uncertainty",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from typing import NamedTuple, List, Tuple, Sequence, Callable\n",
    "from functools import partial\n",
    "\n",
    "import gym\n",
    "from gym import logger\n",
    "import numpy as np\n",
    "import random as orandom\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, jit, grad\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.experimental.optimizers as optimizers\n",
    "from numpy.typing import ArrayLike\n",
    "import more_itertools\n",
    "\n",
    "SEED = 0\n",
    "orandom.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-length",
   "metadata": {},
   "source": [
    "## Environment\n",
    "The DQN agent will be train on the cartpole environment. See [here](https://gym.openai.com/envs/CartPole-v1/) for an explanation if you are unfamiliar with this environment.\n",
    "\n",
    "![Cartpole](media/cartpole.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increasing-visiting",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "cartpole = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-ensemble",
   "metadata": {},
   "source": [
    "## Experience Replay\n",
    "Let's start by defining an experience replay buffer to store transitions. Transitions will be stored in a simple list, and will be converted to jax arrays only when needed for training, to avoid storing all the transitions on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "recreational-nerve",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Transition(NamedTuple):\n",
    "    state: ArrayLike\n",
    "    action: int\n",
    "    reward: float\n",
    "    next_state: ArrayLike\n",
    "    done: bool\n",
    "\n",
    "        \n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer.\"\"\"\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity: int = capacity\n",
    "        self.data: List[Transition] = []\n",
    "        self.index = 0 # index of the next element to insert in self.data\n",
    "        \n",
    "    def store(self, transition: Transition) -> None:\n",
    "        \"\"\"Store a transition.\"\"\"\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(transition)\n",
    "        else:\n",
    "            self.data[self.index] = transition\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size: int) -> List[Transition]:\n",
    "        \"\"\"Sample a batch of transitions.\"\"\"\n",
    "        return orandom.sample(self.data, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "\n",
    "Batch = Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray, jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "def sample_minibatch(batch_size: int, replay_buffer: ReplayBuffer) -> Batch:\n",
    "    \"\"\"Sample transitions from replay buffer and convert it to a training batch.\"\"\"\n",
    "    transitions = replay_buffer.sample(batch_size)\n",
    "    s, a, r, s_, d = zip(*transitions)\n",
    "    return (\n",
    "        jnp.asarray(s),\n",
    "        jnp.asarray(a, dtype=jnp.int8),\n",
    "        jnp.asarray(r, dtype=jnp.float32),\n",
    "        jnp.asarray(s_),\n",
    "        jnp.asarray(d, dtype=jnp.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-handle",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Jax transformations (`jit`, `grad` and`vmap`) are designed to be used on functions that are functionnally pure. \n",
    "This means that all the input data of a function should be given as parameters, and all outputs should be returned by the function.\n",
    "Additionally, any call to the function with the same parameters should return the same output.\n",
    "\n",
    "Knowing this, it is not possible to define models similar to Tensorflow/Pytorch if we are to use compilation and differenciation. \n",
    "In those other frameworks, models are typically stateful objects, holding the weights as attributes. \n",
    "This is incompatible with the pure function definition, because weights are not given as parameters to function and are modified without being returned as outputs.\n",
    "What is typically done in JAX is to pass weights as a parameter to a forward pass function.\n",
    "\n",
    "Let's define a few components which would help defining a fully connected neural network.\n",
    "\n",
    "Let's first define the structure of the NN. \n",
    "A layer will be a named tuple holding the weights and the biases, and a network will be a tuple of layers.\n",
    "Note the use of immutable data structure: network parameters will not be modified in place, but a new set of parameters will be created after each optimization step, to stick to the pure function philosophy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "protected-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayerParams(NamedTuple):\n",
    "    \"\"\"Holds parameters of a fully connected layer.\"\"\"\n",
    "    weights: jnp.ndarray\n",
    "    biases: jnp.ndarray\n",
    "\n",
    "FCNetworkParams = Tuple[FCLayerParams]  # A network is a sequence of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-mercy",
   "metadata": {},
   "source": [
    "Now let's define functions to initialize a network.\n",
    "\n",
    "Note the use of `key` parameters. JAX deals with randomness differently from NumPy, to be more reproductible, parallelizable and vectorisable. More details can be found [here](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html?highlight=random#random-numbers-in-jax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "varied-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer_params(\n",
    "    input_dim: int, output_dim: int, key: jnp.ndarray\n",
    ") -> FCLayerParams:\n",
    "    \"\"\"Kaiming He initialisation of weights for a fully connected layer.\"\"\"\n",
    "    scale = np.sqrt(2. / input_dim) \n",
    "    weights = scale * random.normal(key, (output_dim, input_dim))\n",
    "    biases = jnp.zeros(output_dim)\n",
    "    return FCLayerParams(weights, biases)\n",
    "\n",
    "\n",
    "def init_network_params(sizes: Sequence[int], key: jnp.ndarray) -> FCNetworkParams:\n",
    "    \"\"\"Initialize a fully connected network from layers sizes.\"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return tuple(\n",
    "        init_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-clock",
   "metadata": {},
   "source": [
    "Now that we defined the structure and the initialization of a network, all is left to create is a forward function to predict the output of the network from the input.\n",
    "\n",
    "Because this function will be used a lot of time, let's compile it with the `jit` decorator for faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "closing-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def forward(params: FCNetworkParams, inputs: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Get the output of a fully connected network.\"\"\"\n",
    "    for layer in params:\n",
    "        outputs = jnp.dot(layer.weights, inputs) + layer.biases\n",
    "        inputs = nn.relu(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-modeling",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Let's now define some hypereparameters for the training of our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "particular-aluminum",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "state_dim = cartpole.observation_space.shape[0]\n",
    "action_size = cartpole.action_space.n\n",
    "LAYER_SIZES = [state_dim, 32, 32, action_size]\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE =  64 \n",
    "\n",
    "# RLinput\n",
    "GAMMA = 0.95\n",
    "TAU = 0.01\n",
    "BUFFER_SIZE = 1000000\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_MAX = 1.0\n",
    "EPSILON_DECAY = 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-consent",
   "metadata": {},
   "source": [
    "# Exploration Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "elementary-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def greedy_action(params: FCNetworkParams, state: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Compute greedy action w.r.t to network parameters.\"\"\"\n",
    "    Q = forward(params, state)\n",
    "    return jnp.argmax(Q)\n",
    "\n",
    "\n",
    "def epsilon_greedy(env, epsilon, params, state):\n",
    "    \"\"\"Compute an epsilon greey action\"\"\"\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = int(greedy_action(params, state))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-newsletter",
   "metadata": {},
   "source": [
    "## Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "operational-edgar",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def td_error(\n",
    "    params: FCNetworkParams,\n",
    "    target_params: FCNetworkParams,\n",
    "    s: jnp.ndarray,\n",
    "    a: int,\n",
    "    r: float,\n",
    "    s_: jnp.ndarray,\n",
    "    d: float,\n",
    ") -> float:\n",
    "    \"\"\"Compute the TD error for one sampled transition.\"\"\"\n",
    "    target_Q = jnp.max(forward(target_params, s_))\n",
    "    target = r + GAMMA * (1 - d) * jax.lax.stop_gradient(target_Q)\n",
    "    Q = forward(params, s)[a]\n",
    "    return target - Q\n",
    "\n",
    "\n",
    "def loss(params: FCNetworkParams, target_params: FCNetworkParams, batch: Batch):\n",
    "    \"\"\"Compute the loss on a batch.\"\"\"\n",
    "    # Vectorized version of the td_error function\n",
    "    batched_td_errors = vmap(partial(td_error, params, target_params), in_axes=[0] * 5)\n",
    "    # Apply this function to batch\n",
    "    td_errors_values = batched_td_errors(*batch)\n",
    "    return jnp.mean(jnp.square(td_errors_values))\n",
    "    \n",
    "\n",
    "def actor_learning_step(\n",
    "    opt_update: Callable,\n",
    "    opt_state: optimizers.OptimizerState,\n",
    "    params: FCNetworkParams,\n",
    "    target_params: FCNetworkParams,\n",
    "    step: int,\n",
    "    batch: Batch,\n",
    ") -> optimizers.OptimizerState:\n",
    "    \"\"\"Run a step of learning for the actor.\"\"\"\n",
    "    grads = grad(loss)(params, target_params, batch)\n",
    "#     grads = optimizers.clip_grads(grads, 1)\n",
    "    return opt_update(step, grads, opt_state)\n",
    "\n",
    "\n",
    "# TODO tree_multimap explanation and static param tau\n",
    "@jit\n",
    "def soft_update(\n",
    "    params: FCNetworkParams, target_params: FCNetworkParams, tau: float\n",
    ") -> FCNetworkParams:\n",
    "    \"\"\"Update the target parameters towards actor's with momentum tau.\"\"\"\n",
    "    return jax.tree_multimap(\n",
    "        lambda p, target_p: tau * p + (1 - tau) * target_p,\n",
    "        params,\n",
    "        target_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env: gym.Env, max_episode: int):\n",
    "    \"\"\"Train a DQN neural network on env for max_episode.\"\"\"\n",
    "    # Initialize parameters\n",
    "    params = init_network_params(LAYER_SIZES, random.PRNGKey(SEED))\n",
    "    target_params = params\n",
    "\n",
    "    # Initialize optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.adam(LEARNING_RATE)\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    memory = ReplayBuffer(BUFFER_SIZE)\n",
    "\n",
    "    # jit compile the actor learning step\n",
    "    _actor_step = jit(partial(actor_learning_step, opt_update))\n",
    "    _sample_minibatch = partial(sample_minibatch, BATCH_SIZE)\n",
    "\n",
    "    # Initialize metrics variables\n",
    "    scores = [0] * max_episode\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    epsilon = EPSILON_MAX\n",
    "    opt_step = 0\n",
    "\n",
    "    for episode in range(max_episode):\n",
    "        while not done:\n",
    "            action = epsilon_greedy(env, epsilon, params, state)\n",
    "\n",
    "            # Environment step\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.store(Transition(state, action, reward, next_state, done))\n",
    "            scores[episode] += reward\n",
    "\n",
    "            # Training step\n",
    "            if len(memory) > BATCH_SIZE:\n",
    "                opt_step += 1\n",
    "                batch = _sample_minibatch(memory)\n",
    "                opt_state = _actor_step(opt_state, params, target_params, opt_step, batch)\n",
    "                params = get_params(opt_state)\n",
    "\n",
    "                target_params = soft_update(params, target_params, TAU)\n",
    "                epsilon = max(epsilon * EPSILON_DECAY, EPSILON_MIN)\n",
    "\n",
    "            state = next_state\n",
    "        \n",
    "        # Early stopping\n",
    "        if np.mean(scores[episode-4:episode+1]) > 195:\n",
    "            print(f\"Environment solved in {episode} episodes\")\n",
    "            scores = scores[:episode]\n",
    "            break\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(\n",
    "                f\"Episode {episode}\",\n",
    "                f\", epsilon {epsilon:.2f}\",\n",
    "                f\", episode return {scores[episode]:.1f}\",\n",
    "                sep=\"\",\n",
    "            )\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "    return scores, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "color-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, epsilon 1.00, episode return 14.0\n",
      "Episode 10, epsilon 0.48, episode return 10.0\n",
      "Episode 20, epsilon 0.27, episode return 11.0\n",
      "Episode 30, epsilon 0.16, episode return 11.0\n",
      "Episode 40, epsilon 0.10, episode return 11.0\n",
      "Episode 50, epsilon 0.06, episode return 10.0\n",
      "Episode 60, epsilon 0.03, episode return 14.0\n",
      "Episode 70, epsilon 0.01, episode return 49.0\n",
      "Episode 80, epsilon 0.01, episode return 95.0\n",
      "Episode 90, epsilon 0.01, episode return 208.0\n",
      "Environment solved in 91 episodes\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'episodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5b05300dcca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartpole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-bca5376e6b43>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, max_episode)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m195\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Environment solved in {episode} episodes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'episodes' is not defined"
     ]
    }
   ],
   "source": [
    "scores, params = train(cartpole, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "south-entry",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "biblical-calculator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rollout(params: FCNetworkParams, env: gym.Env, render:bool = False):\n",
    "    s = env.reset()\n",
    "    d = False\n",
    "    score = 0\n",
    "    if render:\n",
    "        env.render()\n",
    "    while not d:\n",
    "        s, r, d, _ = env.step(int(greedy_action(params, s)))\n",
    "        score += r\n",
    "        if render:\n",
    "            env.render()\n",
    "    return score\n",
    "\n",
    "rollout(params, cartpole, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "disturbed-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454.4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(params: FCNetworkParams, env: gym.Env, n_episodes:int = 100):\n",
    "    scores = []\n",
    "    for _ in range(100):\n",
    "        scores.append(rollout(params, cartpole))\n",
    "    return np.mean(scores)\n",
    "\n",
    "evaluate(params, cartpole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-validation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
