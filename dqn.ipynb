{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "harmful-converter",
   "metadata": {},
   "source": [
    "# DQN implementation in JAX\n",
    "\n",
    "This notebook walks through an implementation of [DQN](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf) in [JAX](https://jax.readthedocs.io/en/latest/).\n",
    "There exists a complete [ecosystem](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) of libraries based on JAX to ease the developpement of deep and Reinforcement Learning algorithms, but because this notebook aims at demonstrating its core concepts, the implementation will only rely on \"vanilla\" JAX.\n",
    "\n",
    "## JAX\n",
    "From the official [quickstart](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) documentation:\n",
    "> JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.\n",
    "\n",
    "JAX is based on [XLA](https://www.tensorflow.org/xla) to provide a hardware accelerated backend to linear algebra operations, encapsulated in a NumPy-compatible API. To keep it simple, any numpy code can be replaced by its equivalent jax.numpy to be ported on GPU/TPU and run faster. \n",
    "Moreover, all these operations, as well as some native Python code, can be automatically differentiated, making JAX a good candidate to perform any kind of gradient based optimization.\n",
    "\n",
    "JAX can be defined it as \"an extensible system for composable function transformations\".\n",
    "The most useful transformations include:\n",
    "* `grad`: Automatic differentiation transformation, `grad(func)` returns a function which is the gradient of `func`.\n",
    "* `jit`: \"Just in Time\" compilation. Remember that each JAX array operation rely on a hardware accelerated backend ? Well, your code will most probably contains sequences of this operation, which would result in the backend being called sequentially to execute them. By compiling a sequence of operations, the backend could be called only once for the whole sequence, resulting in faster execution. \n",
    "* `vmap`: Automatic vectorisation transformation, can be used to easily apply operation to full batch instead of single elements.\n",
    "\n",
    "All these transformations can be composed arbitrarily, you can take the gradient of a compiled vectorized funtcion for example: `grad(jit(vmap(f)))`. \n",
    "This transformation system may seem abstract for now, but the notebook contains example use cases for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painted-senator",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from typing import NamedTuple, List, Tuple, Sequence, Callable\n",
    "from functools import partial\n",
    "\n",
    "import gym\n",
    "from gym import logger\n",
    "import numpy as np\n",
    "import random as orandom\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, jit, grad\n",
    "import jax\n",
    "import jax.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.experimental.optimizers as optimizers\n",
    "import more_itertools\n",
    "\n",
    "SEED = 0\n",
    "orandom.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-reputation",
   "metadata": {},
   "source": [
    "## Environment\n",
    "The DQN agent will be train on the cartpole environment. See [here](https://gym.openai.com/envs/CartPole-v1/) for an explanation if you are unfamiliar with this environment.\n",
    "\n",
    "![Cartpole](media/cartpole.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "located-wright",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "cartpole = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-spiritual",
   "metadata": {},
   "source": [
    "## Experience Replay\n",
    "Let's start by defining an experience replay buffer to store transitions. Transitions will be stored in a simple list, and will be converted to jax arrays only when needed for training, to avoid storing all the replay buffer on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-horizon",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Transition(NamedTuple):\n",
    "    state: np.ndarray  # nunmpy array as it is on the cpu\n",
    "    action: int\n",
    "    reward: float\n",
    "    next_state: np.ndarray\n",
    "    done: bool\n",
    "\n",
    "        \n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer.\"\"\"\n",
    "    def __init__(self, capacity: int):\n",
    "        self.capacity: int = capacity\n",
    "        self.data: List[Transition] = []\n",
    "        self.index = 0 # index of the next element to insert in self.data\n",
    "        \n",
    "    def store(self, transition: Transition) -> None:\n",
    "        \"\"\"Store a transition.\"\"\"\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(transition)\n",
    "        else:\n",
    "            self.data[self.index] = transition\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size: int) -> List[Transition]:\n",
    "        \"\"\"Sample a batch of transitions.\"\"\"\n",
    "        return orandom.sample(self.data, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "\n",
    "Batch = Tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray, jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "def sample_minibatch(batch_size: int, replay_buffer: ReplayBuffer) -> Batch:\n",
    "    \"\"\"Sample transitions from replay buffer and convert it to a training batch.\"\"\"\n",
    "    transitions = replay_buffer.sample(batch_size)\n",
    "    s, a, r, s_, d = zip(*transitions)\n",
    "    return (\n",
    "        jnp.asarray(s),\n",
    "        jnp.asarray(a, dtype=jnp.int8),\n",
    "        jnp.asarray(r, dtype=jnp.float32),\n",
    "        jnp.asarray(s_),\n",
    "        jnp.asarray(d, dtype=jnp.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-showcase",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Jax transformations (`jit`, `grad` and`vmap`) are designed to be used on functions that are functionnally pure. \n",
    "This means that all the input data of a function should be given as parameters, and all outputs should be returned by the function.\n",
    "Additionally, any call to the function with the same parameters should return the same outputs.\n",
    "\n",
    "Knowing this, it is not possible to define models similar to Tensorflow/Pytorch if we are to use compilation and differenciation. \n",
    "In those other frameworks, models are typically stateful objects, holding the weights as attributes. \n",
    "This is incompatible with the pure function definition, because weights are not given as parameters to function and are modified without being returned as outputs.\n",
    "What is typically done in JAX is to pass weights as a parameter to a forward pass function.\n",
    "\n",
    "Let's define a few components which would help defining a fully connected neural network.\n",
    "\n",
    "Let's first define the structure of the NN. \n",
    "A layer will be a named tuple holding the weights and the biases, and a network will be a tuple of layers.\n",
    "Note the use of immutable data structure: network parameters will not be modified in place, but a new set of parameters will be created after each optimization step, to stick to the pure function philosophy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "economic-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayerParams(NamedTuple):\n",
    "    \"\"\"Holds parameters of a fully connected layer.\"\"\"\n",
    "    weights: jnp.ndarray\n",
    "    biases: jnp.ndarray\n",
    "\n",
    "FCNetworkParams = Tuple[FCLayerParams]  # A network is a sequence of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-greensboro",
   "metadata": {},
   "source": [
    "Now let's define functions to initialize a network.\n",
    "\n",
    "Note the use of `key` parameters. JAX deals with randomness differently from NumPy, as numpy actually rely on a state (inferred from the seed) to provide pseudo-randomness. Each random number generated is actually inferred deterministically from this state, and the state is modified after each number generation. This would be a contradiction with the Jax functional programming phylosophy. Thus, JAX requires to pass the state (~ the key) as a parameter. More details can be found [here](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html?highlight=random#random-numbers-in-jax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bright-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_layer_params(\n",
    "    input_dim: int, output_dim: int, key: jnp.ndarray\n",
    ") -> FCLayerParams:\n",
    "    \"\"\"Kaiming He initialisation of weights for a fully connected layer.\"\"\"\n",
    "    scale = np.sqrt(2. / input_dim) \n",
    "    weights = scale * random.normal(key, (output_dim, input_dim))\n",
    "    biases = jnp.zeros(output_dim)\n",
    "    return FCLayerParams(weights, biases)\n",
    "\n",
    "\n",
    "def init_network_params(sizes: Sequence[int], key: jnp.ndarray) -> FCNetworkParams:\n",
    "    \"\"\"Initialize a fully connected network from layers sizes.\"\"\"\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return tuple(\n",
    "        init_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-rainbow",
   "metadata": {},
   "source": [
    "Now that we defined the structure and the initialization of a network, all is left to create is a forward function to predict the output of the network from the input.\n",
    "\n",
    "Because this function will be used a lot of time, let's compile it with the `jit` decorator for faster execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removed-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def forward(params: FCNetworkParams, inputs: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Get the output of a fully connected network.\"\"\"\n",
    "    for layer in params:\n",
    "        outputs = jnp.dot(layer.weights, inputs) + layer.biases\n",
    "        inputs = nn.relu(outputs)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-excess",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Let's now define some hypereparameters for the training of our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appropriate-quest",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "state_dim = cartpole.observation_space.shape[0]\n",
    "action_size = cartpole.action_space.n\n",
    "LAYER_SIZES = [state_dim, 32, 32, action_size]\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE =  64 \n",
    "\n",
    "# RLinput\n",
    "GAMMA = 0.95\n",
    "TAU = 0.01\n",
    "BUFFER_SIZE = 1000000\n",
    "EPSILON_MIN = 0.001\n",
    "EPSILON_MAX = 1.0\n",
    "EPSILON_DECAY = 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-ballot",
   "metadata": {},
   "source": [
    "# Exploration Policy\n",
    "\n",
    "The exploration policy used will be an epsilon greedy policy. The implementation is very classic, just note the use of the numpy-like function jnp.argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hidden-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def greedy_action(params: FCNetworkParams, state: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"Compute greedy action w.r.t to network parameters.\"\"\"\n",
    "    Q = forward(params, state)\n",
    "    return jnp.argmax(Q)\n",
    "\n",
    "\n",
    "def epsilon_greedy(env, epsilon, params, state):\n",
    "    \"\"\"Compute an epsilon greey action\"\"\"\n",
    "    if np.random.rand() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = int(greedy_action(params, state))\n",
    "    return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-consistency",
   "metadata": {},
   "source": [
    "## DQN specific functions\n",
    "\n",
    "Let's now write DQN core functions. \n",
    "The computation of the TD error on each transition in a batch provides a good example of the usage of `vmap`. \n",
    "The function `td_error` actually computes the error on only one transition, so that we don't have to worry about the additional dimension. \n",
    "This funciton is then verctorized automatically using `vmap` into the `batched_td_errors` function, which will compute the TD error of every transition in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "banned-reference",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def td_error(\n",
    "    params: FCNetworkParams,\n",
    "    target_params: FCNetworkParams,\n",
    "    s: jnp.ndarray,\n",
    "    a: int,\n",
    "    r: float,\n",
    "    s_: jnp.ndarray,\n",
    "    d: float,\n",
    ") -> float:\n",
    "    \"\"\"Compute the TD error for one sampled transition.\"\"\"\n",
    "    target_Q = jnp.max(forward(target_params, s_))\n",
    "    target = r + GAMMA * (1 - d) * jax.lax.stop_gradient(target_Q)\n",
    "    Q = forward(params, s)[a]\n",
    "    return target - Q\n",
    "\n",
    "\n",
    "def loss(params: FCNetworkParams, target_params: FCNetworkParams, batch: Batch):\n",
    "    \"\"\"Compute the loss on a batch.\"\"\"\n",
    "    # Vectorized version of the td_error function\n",
    "    batched_td_errors = vmap(td_error, in_axes=[None, None, 0, 0, 0, 0, 0])\n",
    "    # Apply this function to batch\n",
    "    td_errors_values = batched_td_errors(params, target_params, *batch)\n",
    "    return jnp.mean(jnp.square(td_errors_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-cutting",
   "metadata": {},
   "source": [
    "Now that we have the loss function, we can write the function computing one step of gradient descent on an actor network.\n",
    "\n",
    "Before we do that, we would need to look at JAX optimization package. \n",
    "This package is actually experimental, but Reinforcement learning is unstable enough to require some advanced optimizers instead of vanilla gradient descent.\n",
    "\n",
    "Let's first think about how we would create an optimizer in Pytorch or tensorflow. \n",
    "An optimizer would typically be created from the parameters of a network, and keep them as an attribute.\n",
    "Then, each step of optimization would update this attribute in place.\n",
    "\n",
    "This approach can not be used in JAX if we want to compile the code, because it implies mutable state objects and side effects. \n",
    "As an alternative, `jax` proposes this interface:\n",
    "```python \n",
    "opt_init, opt_update, get_params = optimizers.sgd(learning_rate)\n",
    "opt_state = opt_init(params)\n",
    "\n",
    "def step(step, opt_state):\n",
    "    value, grads = jax.value_and_grad(loss_fn)(get_params(opt_state))\n",
    "    opt_state = opt_update(step, grads, opt_state)\n",
    "    return value, opt_state\n",
    "\n",
    "for i in range(num_steps):\n",
    "    value, opt_state = step(i, opt_state)\n",
    "```\n",
    "\n",
    "The idea is that initializing an optimizer creates three functions, an initializer, which would create the state of the optimizer from a set of parameters, an update function, which would return a new state from an existing one after a step of optimization, and a function to access the parameters of a given state.\n",
    "\n",
    "What would we need then to compute a step of learning ? \n",
    "We would need the optimizer update function, the current optimizer state, and the parameters to the loss function. \n",
    "Additionally, we need an additional `step` argument which is consumed by the `opt_update`. \n",
    "\n",
    "Note that in this function, we actually never compute the loss value. \n",
    "We derive the gradient function using the `grad` transformation, and the compute the gradient value directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "horizontal-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actor_learning_step(\n",
    "    opt_update: Callable,\n",
    "    opt_state: optimizers.OptimizerState,\n",
    "    step: int,\n",
    "    *loss_attributes\n",
    ") -> optimizers.OptimizerState:\n",
    "    \"\"\"Run a step of learning for the actor.\"\"\"\n",
    "    grads = grad(loss)(*loss_attributes)\n",
    "    optimizers.clip_grads(grads, 1)\n",
    "    return opt_update(step, grads, opt_state)\n",
    "\n",
    "\n",
    "# TODO tree_multimap explanation\n",
    "@jit\n",
    "def soft_update(\n",
    "    params: FCNetworkParams, target_params: FCNetworkParams\n",
    ") -> FCNetworkParams:\n",
    "    \"\"\"Update the target parameters towards actor's with momentum tau.\"\"\"\n",
    "    return jax.tree_multimap(\n",
    "        lambda p, target_p: TAU * p + (1 - TAU) * target_p,\n",
    "        params,\n",
    "        target_params,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-drilling",
   "metadata": {},
   "source": [
    "Note that there is no `jit` decorator above the `actor_learning_step` function. \n",
    "The problem here is that the first argument is a Callable, and thus could not traced. \n",
    "The solution here would be to create a [curried](https://en.wikipedia.org/wiki/Currying) function from `actor_learning_step`, once the `opt_update` is created.\n",
    "This is done by the expression `partial(actor_learning_step, opt_update)`, which is then wrapped into a `jit` tansformation to be compiled. \n",
    "\n",
    "We are now ready for the training script !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medieval-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env: gym.Env, max_episode: int):\n",
    "    \"\"\"Train a DQN neural network on env for max_episode.\"\"\"\n",
    "    # Initialize parameters\n",
    "    params = init_network_params(LAYER_SIZES, random.PRNGKey(SEED))\n",
    "    target_params = params\n",
    "\n",
    "    # Initialize optimizer\n",
    "    opt_init, opt_update, get_params = optimizers.adam(LEARNING_RATE)\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    # Replay buffer\n",
    "    memory = ReplayBuffer(BUFFER_SIZE)\n",
    "    _sample_minibatch = partial(sample_minibatch, BATCH_SIZE)\n",
    "\n",
    "\n",
    "    # jit compile the actor learning step\n",
    "    _actor_step = jit(partial(actor_learning_step, opt_update))\n",
    "\n",
    "    # Initialize metrics variables\n",
    "    scores = [0] * max_episode\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    epsilon = EPSILON_MAX\n",
    "    opt_step = 0\n",
    "\n",
    "    for episode in range(max_episode):\n",
    "        while not done:\n",
    "            action = epsilon_greedy(env, epsilon, params, state)\n",
    "\n",
    "            # Environment step\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            memory.store(Transition(state, action, reward, next_state, done))\n",
    "            scores[episode] += reward\n",
    "\n",
    "            # Training step\n",
    "            if len(memory) > BATCH_SIZE:\n",
    "                opt_step += 1\n",
    "                batch = _sample_minibatch(memory)\n",
    "                opt_state = _actor_step(opt_state, opt_step, params, target_params, batch)\n",
    "                params = get_params(opt_state)\n",
    "\n",
    "                # Update target and epsilon\n",
    "                target_params = soft_update(params, target_params)\n",
    "                epsilon = max(epsilon * EPSILON_DECAY, EPSILON_MIN)\n",
    "\n",
    "            state = next_state\n",
    "        \n",
    "        # Early stopping\n",
    "        if np.mean(scores[episode-9:episode+1]) > 195:\n",
    "            print(f\"Environment solved in {episode} episodes\")\n",
    "            scores = scores[:episode]\n",
    "            break\n",
    "\n",
    "        if episode % 10 == 0:\n",
    "            print(\n",
    "                f\"Episode {episode}\",\n",
    "                f\", epsilon {epsilon:.2f}\",\n",
    "                f\", episode return {scores[episode]:.1f}\",\n",
    "                sep=\"\",\n",
    "            )\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "    return scores, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "personal-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "/home/vcoyette/miniconda3/envs/jax_playground/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vcoyette/miniconda3/envs/jax_playground/lib/python3.8/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, epsilon 1.00, episode return 23.0\n",
      "Episode 10, epsilon 0.52, episode return 11.0\n",
      "Episode 20, epsilon 0.28, episode return 17.0\n",
      "Episode 30, epsilon 0.16, episode return 12.0\n",
      "Episode 40, epsilon 0.09, episode return 12.0\n",
      "Episode 50, epsilon 0.06, episode return 10.0\n",
      "Episode 60, epsilon 0.03, episode return 10.0\n",
      "Episode 70, epsilon 0.00, episode return 133.0\n",
      "Episode 80, epsilon 0.00, episode return 92.0\n",
      "Episode 90, epsilon 0.00, episode return 140.0\n",
      "Environment solved in 98 episodes\n"
     ]
    }
   ],
   "source": [
    "scores, params = train(cartpole, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tough-purpose",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electronic-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rollout(params: FCNetworkParams, env: gym.Env, render:bool = False):\n",
    "    s = env.reset()\n",
    "    d = False\n",
    "    score = 0\n",
    "    if render:\n",
    "        env.render()\n",
    "    while not d:\n",
    "        s, r, d, _ = env.step(int(greedy_action(params, s)))\n",
    "        score += r\n",
    "        if render:\n",
    "            env.render()\n",
    "    return score\n",
    "\n",
    "rollout(params, cartpole, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "round-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263.76"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(params: FCNetworkParams, env: gym.Env, n_episodes:int = 100):\n",
    "    scores = []\n",
    "    for _ in range(100):\n",
    "        scores.append(rollout(params, cartpole))\n",
    "    return np.mean(scores)\n",
    "\n",
    "evaluate(params, cartpole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-emerald",
   "metadata": {},
   "source": [
    "According to the documentation, the environment is solved if the mean of the return over 100 episodes is more than 195. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
